# =============================================================================
# Weft Docker Compose Configuration - Registry Images
# =============================================================================
# Production environment using pre-built images from GitHub Container Registry.
#
# This compose file pulls images from ghcr.io instead of building locally.
# Use this for quick deployment without building Docker images.
#
# Services:
#   - db: PostgreSQL 16 database
#   - frontend: React + Vite frontend service (nginx)
#   - voice-emotion-recognition: Python SpeechBrain service for voice emotion detection
#   - backend: Node.js backend service
#
# Usage:
#   docker compose -f docker/docker-compose.registry.yml up -d
#   docker compose -f docker/docker-compose.registry.yml down
#   docker compose -f docker/docker-compose.registry.yml logs -f
# =============================================================================

services:
  # ---------------------------------------------------------------------------
  # PostgreSQL Database
  # ---------------------------------------------------------------------------
  db:
    image: postgres:16-alpine
    container_name: weft-postgres
    restart: unless-stopped
    environment:
      POSTGRES_USER: ${POSTGRES_USER:-weft}
      POSTGRES_PASSWORD: ${POSTGRES_PASSWORD:-weft_dev_password}
      POSTGRES_DB: ${POSTGRES_DB:-weft}
      PGDATA: /var/lib/postgresql/data/pgdata
    ports:
      - "${POSTGRES_PORT:-5432}:5432"
    volumes:
      - postgres_data:/var/lib/postgresql/data
    healthcheck:
      test: ["CMD-SHELL", "pg_isready -U ${POSTGRES_USER:-weft} -d ${POSTGRES_DB:-weft}"]
      interval: 10s
      timeout: 5s
      retries: 5
      start_period: 10s
    networks:
      - weft-network
    # Optimize PostgreSQL settings
    command:
      - "postgres"
      - "-c"
      - "max_connections=200"
      - "-c"
      - "shared_buffers=256MB"
      - "-c"
      - "effective_cache_size=1GB"
      - "-c"
      - "maintenance_work_mem=64MB"
      - "-c"
      - "checkpoint_completion_target=0.9"
      - "-c"
      - "wal_buffers=16MB"
      - "-c"
      - "default_statistics_target=100"
      - "-c"
      - "random_page_cost=1.1"
      - "-c"
      - "effective_io_concurrency=200"
      - "-c"
      - "work_mem=1310kB"
      - "-c"
      - "min_wal_size=1GB"
      - "-c"
      - "max_wal_size=4GB"

  # ---------------------------------------------------------------------------
  # Frontend Service (from ghcr.io)
  # ---------------------------------------------------------------------------
  frontend:
    image: ghcr.io/wazoakarapace/weft-frontend:latest
    container_name: weft-frontend
    restart: unless-stopped
    ports:
      - "${FRONTEND_PORT:-3000}:3000"
    healthcheck:
      test: ["CMD", "wget", "--no-verbose", "--tries=1", "--spider", "http://localhost:3000/"]
      interval: 30s
      timeout: 10s
      retries: 3
      start_period: 10s
    networks:
      - weft-network

  # ---------------------------------------------------------------------------
  # Voice Emotion Recognition Service (from ghcr.io)
  # ---------------------------------------------------------------------------
  voice-emotion-recognition:
    image: ghcr.io/wazoakarapace/weft-voice-emotion:latest
    container_name: weft-voice-emotion
    restart: unless-stopped
    environment:
      PYTHONUNBUFFERED: 1
      MODEL_CACHE_DIR: /app/models
    volumes:
      - voice_emotion_models:/app/models
    healthcheck:
      test: ["CMD", "curl", "-f", "http://localhost:8000/health"]
      interval: 30s
      timeout: 10s
      retries: 3
      start_period: 60s
    networks:
      - weft-network

  # ---------------------------------------------------------------------------
  # Backend Service (from ghcr.io)
  # ---------------------------------------------------------------------------
  backend:
    image: ghcr.io/wazoakarapace/weft-backend:latest
    container_name: weft-backend
    restart: unless-stopped
    depends_on:
      db:
        condition: service_healthy
      voice-emotion-recognition:
        condition: service_healthy
    environment:
      PORT: ${BACKEND_PORT:-3001}
      DATABASE_URL: postgresql://${POSTGRES_USER:-weft}:${POSTGRES_PASSWORD:-weft_dev_password}@db:5432/${POSTGRES_DB:-weft}
      BETTER_AUTH_URL: ${BETTER_AUTH_URL:-http://localhost:3001}
      BETTER_AUTH_SECRET: ${BETTER_AUTH_SECRET:-development-secret-key-change-in-production-min-32-chars}
      FRONTEND_URL: ${FRONTEND_URL:-http://localhost:3000}
      VOICE_EMOTION_API_URL: ${VOICE_EMOTION_API_URL:-http://voice-emotion-recognition:8000}
      TRANSCRIPTION_WORKER_CONCURRENCY: 1
    ports:
      - "${BACKEND_PORT:-3001}:3001"
    volumes:
      - uploads_data:/app/uploads
    healthcheck:
      test: ["CMD", "wget", "--no-verbose", "--tries=1", "--spider", "http://localhost:3001/"]
      interval: 30s
      timeout: 10s
      retries: 3
      start_period: 10s
    networks:
      - weft-network
    # Set memory limit to prevent OS OOM kills (16GB for large Whisper models like large-v3)
    deploy:
      resources:
        limits:
          memory: 16G
        reservations:
          memory: 2G

# ---------------------------------------------------------------------------
# Named Volumes
# ---------------------------------------------------------------------------
volumes:
  postgres_data:
    name: weft_postgres_data
    driver: local
  uploads_data:
    name: weft_uploads_data
    driver: local
  voice_emotion_models:
    name: weft_voice_emotion_models
    driver: local

# ---------------------------------------------------------------------------
# Networks
# ---------------------------------------------------------------------------
networks:
  weft-network:
    name: weft-network
    driver: bridge
